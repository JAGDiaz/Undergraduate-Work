\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bbm}
\usepackage{bm}
\usepackage{amsthm}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{psfrag}
\usepackage{color}
\usepackage{url}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{tikz}
\usetikzlibrary{positioning}
\tikzset{main node/.style={circle,fill=gray!20,draw,minimum size=.5cm,inner sep=0pt},}

\definecolor{codegreen}{rgb}{0,0.5,0}
\definecolor{codewhite}{rgb}{1,1,1}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{codeblack}{rgb}{0,0,0}
\definecolor{codeorange}{rgb}{0.8,0.4,0}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{codewhite},   
    commentstyle=\color{codegray},
    keywordstyle=\color{codegreen},
    numberstyle=\color{codegray},
    stringstyle=\color{codeorange},
    basicstyle=\ttfamily ,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=4
}
\lstset{style=mystyle}


\setlength{\hoffset}{-1in}
\addtolength{\textwidth}{1.5in}
\setlength{\voffset}{-1in}
\addtolength{\textheight}{1.5in}
\newcommand{\be}{\begin{enumerate}}
\newcommand{\ee}{\end{enumerate}}
\newcommand{\BigO}[1]{\ensuremath\mathcal{O}\left(#1\right)}
\newcommand{\il}[1]{\lstinline!#1!}
\newcommand{\norm}[1]{\left|\left|#1\right|\right|}
\newcommand{\abs}[1]{\left|#1\right|}
\newcommand{\parens}[1]{\left(#1\right)}
\newcommand{\bracks}[1]{\left\{#1\right\}}
\newcommand{\sqbracks}[1]{\left[#1\right]}
\newcommand{\vep}{\varepsilon}
\newcommand{\ceiling}[1]{\left\lceil#1\right\rceil}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\one}{\mathbbm{1}}
\newcommand{\A}{\mathcal{A}}
\newcommand{\distrib}[2]{\text{#1}\left(#2\right)}
\newcommand{\dd}[1]{\frac{d}{d#1}}
\newcommand{\abracks}[1]{\left< #1\right>}

\newtheorem*{proposition}{Proposition}

\begin{document}
	\begin{center}
		\textbf{Fall 2020, Math 630:\ Homework 4} \\
		\textbf{Due:\ Friday, September 25th, 2020} \\
		\textbf{Joseph Diaz: 819947915}
	\end{center}
\noindent\makebox[\linewidth]{\rule{\paperwidth}{0.4pt}}

\be[(E1)]
    \item Let $X$ be the space of all sequences of the form
    $$x = \parens{x_1,\ x_2,\ x_3,\ \cdots,\ x_n,\ 0,\ 0,\ \cdots},\
    \forall i \in \N,\ x_i \in \R$$
    whose terms are all zeros after some index. We define
    $$\norm{x}_\infty = \max_{i\in\N}\abs{x_i}$$
    \be[1.]
    \item
    Show that $\parens{X, \norm{\cdot}_\infty}$ defines a normed 
    vector space.
    \begin{proof}
    First, we'll show that $X$ is indeed a vector space by defining 
    addition and scalar multiplication in the space and that these 
    and $X$
    satisfy the definition of a vector space. Let $x, y \in X$, and 
    define addition component-wise as 
    \begin{gather*}
    x = \parens{x_1,\ \cdots,\ x_n,\ 0,\ \cdots}, y = \parens{y_1,
    \ \cdots,\ y_m,\ 0,\ \cdots},\ x_i, y_j \in \R, \forall i,j \in 
    \N\\
    \implies x+y = \parens{x_1 + y_1,\ \cdots,\ x_n + y_n,\ 
    \cdots,\ y_m,\ 0,\ \cdots}
    \end{gather*}
    assuming that $m \geq n$, and define scalar multiplication as
    $$\alpha x = \parens{\alpha x_1,\ \cdots,\ \alpha x_n,\ 
    0,\ \cdots}$$
    for $\alpha \in \R$.\\
    
    \textbf{Commutative addition}:\\
    From the definition of addition:
    \begin{align*}
    x + y &= \parens{x_1 + y_1,\ \cdots,\ x_n + y_n,\ 
    \cdots,\ y_m,\ 0,\ \cdots} \\
    &= \parens{y_1 + x_1,\ \cdots,\ y_n + x_n,\ 
    \cdots,\ y_m,\ 0,\ \cdots} \\
    &= y + x
    \end{align*}
    So addition is commutative. We also have that $x_i + y_i =
    y_i + x_i, \forall i$, so $X$ is also closed under addition.\\
    \textbf{Associative addition}:\\
    Let $z \in X$ such that
    $$z = \parens{z_1,\ \cdots,\ z_\ell,\ 0,\ \cdots}$$
    then
    \begin{align*}
    (x + y) + z &=  \parens{x_1 + y_1,\ \cdots,\ x_n + y_n,\ 
    \cdots,\ y_m,\ 0,\ \cdots} + \parens{z_1,\ \cdots,\ z_\ell,\ 
    0,\ \cdots}\\
    &= \parens{(x_1 + y_1) + z_1,\ \cdots,\ (x_n + y_n) + z_n,\ 
    \cdots,\ y_m + z_m,\ \cdots,\ z_\ell,\ 0,\ \cdots} \\
    &= \parens{x_1 + (y_1 + z_1),\ \cdots,\ x_n + (y_n + z_n),\ 
    \cdots,\ (y_m + z_m),\ \cdots,\ z_\ell,\ 0,\ \cdots} \\
    &= \parens{x_1,\ \cdots,\ x_n,\ 0,\ \cdots} + 
    \parens{y_1 + z_1,\ \cdots,\ (y_m + z_m),\ \cdots,\ z_\ell,\ 
    0,\ \cdots} \\
    &= x + (y+z)
    \end{align*}
    assuming that $n \leq m \leq \ell$. So addition is associative.\\
    \textbf{Distributive property on scalars}:\\
    Let $\alpha, \beta \in \R$, then
    \begin{align*}
    \parens{\alpha + \beta}x &= \parens{(\alpha + \beta)x_1,\ 
    \cdots,\ (\alpha + \beta)x_n,\ 0,\ \cdots} \\
    &= \parens{\alpha x_1 + \beta x_1,\ 
    \cdots,\ \alpha x_n + \beta x_n,\ 0,\ \cdots} \\
    &= \alpha\parens{x_1,\ \cdots,\ x_n,\ 0,\ \cdots} + 
    \beta\parens{x_1,\ \cdots,\ x_n,\ 0,\ \cdots} \\
    &= \alpha x + \beta x 
    \end{align*}
    So multiplication distributes over sums of scalars.\\
    \textbf{Distributive property on vectors}:\\
    We have that
    \begin{align*}
    \alpha(x+y) &= \alpha\parens{x_1 + y_1,\ \cdots,\ x_n + y_n,\ 
    \cdots,\ y_m,\ 0,\ \cdots} \\
    &= \parens{\alpha(x_1 + y_1),\ \cdots,\ \alpha(x_n + y_n),\ 
    \cdots,\ \alpha y_m,\ 0,\ \cdots} \\
    &= \parens{\alpha x_1 + \alpha y_1,\ \cdots,\ 
    \alpha x_n + \alpha y_n,\ \cdots,\ \alpha y_m,\ 0,\ \cdots} \\
    &= \parens{\alpha x_1,\ \cdots,\ \alpha x_n,\ 0,\ \cdots}  +
    \parens{\alpha y_1,\ \cdots,\ \alpha y_m,\ 0,\ \cdots} \\
    &= \alpha x + \alpha y
    \end{align*}
    So multiplication distributes over sums of vectors.\\
    \textbf{Associative scalar multiplication}:\\
    we have that
    \begin{align*}
    (\alpha\beta)x &= \parens{(\alpha\beta) x_1,\ \cdots,\ (\alpha
    \beta)x_n,\ 0,\ \cdots} \\
    &= \parens{\alpha(\beta x_1),\ \cdots,\ \alpha
    (\beta x_n),\ 0,\ \cdots} \\
    &= \alpha\parens{\beta x_1,\ \cdots,\ 
    \beta x_n,\ 0,\ \cdots} \\
    &= \alpha\parens{\beta x}
    \end{align*}
    So scalar multiplication is associative.
    \textbf{Scalar multiplicative identity}:\\
    $1$ is the multiplicative identity in $\R$, so
    $$1\cdot x = \parens{x_1,\ \cdots,\ x_n,\ 0,\ \cdots} = x$$
    So $X$ has a scalar multiplicative identity.\\
    \textbf{Additive identity}:\\
    Let $\vec{0} = \parens{0,\ 0,\ \cdots}$, then $\forall x \in X$
    $$\vec{0} 
    + x = \parens{x_1,\ \cdots,\ x_n,\ 0,\ \cdots} = x +
    \vec{0} = x$$
    So $X$ has an additive identity.
    \textbf{Additive inverse}:\\
    $\forall x \in X, \exists x' \in X$ such that $x' = -x = 
    \parens{-x_1,\ \cdots,\ -x_n,\ 0,\ \cdots}$, then by the 
    definition of addition
    $$x + x' = x' + x = \vec{0}$$
    So $X$ has additive inverses.\\\\
    $X$ satisfies all the properties of a vector space, so 
    $X$ is a vector space.\\\\
    

    Now we'll show that $\norm{\cdot}_\infty$ has the properties of a 
    norm on $X$, let $x,y \in X$.\\\\
    \textbf{Non-negativity and Identity}:\\
    The non-negativity of $\norm{\cdot}_\infty$ is trivial, as it
    is defined as the max among non-negative items; so it can't be
    negative.
    We'll show the identity property from the left and right.
    \be
    \item[$\Longrightarrow$:] We have that $\norm{x}_\infty = 0$,
    which means that $\max_{i\in\N}\abs{x_i} = 0$. This implies that
    $x_i = 0,\ \forall i \in \N$, which is to say that $x = 
    \parens{0,\ 0,\ \cdots} = \vec{0}$.
    
    \item[$\Longleftarrow$:] We have that $x = \parens{0,\ 0,\
    \cdots} = \vec{0}$. So 
    $$\norm{x}_\infty = \max_{i\in\N}\abs{x_i} = \max_{i\in\N}\abs{0}
    = 0$$
    \ee
    So $\norm{\cdot}_\infty$ satisfies both of those properties.\\
    \textbf{Homogeneity}:\\
    Let $\alpha \in \R$, now
    \begin{align*}
    \norm{\alpha x}_\infty &= \max_{i\in\N}\abs{\alpha x_i} \\
    &= \abs{\alpha}\max_{i\in\N}\abs{x_i} \\
    &= \abs{\alpha}\norm{x}_\infty
    \end{align*}     
    So $\norm{\cdot}_\infty$ has the homogeneity property.\\
    \textbf{Triangle Inequality}:\\
    \begin{align*}
    \norm{x + y}_\infty &= \max_{i\in\N}\abs{x_i + y_i} \\
    &\leq  \max_{i\in\N}\parens{\abs{x_i} + \abs{y_i}} \\
    &= \max_{i\in\N}\abs{x_i} + \max_{i\in\N}\abs{y_i} \\
    &= \norm{x}_\infty + \norm{y}_\infty
    \end{align*}
    So $\norm{\cdot}_\infty$ respects the triangle inequality.\\\\
    $\norm{\cdot}_\infty$ satisfies all the properties of a norm on
    $X$, so $\parens{X,\norm{\cdot}_\infty}$ is a normed vector 
    space.
    \end{proof}
    
    \item
    Show that $X$ is not complete.
    \begin{proof}
    We'll show this by way of contradiction; first, suppose that $X$
    is a complete space.\\\\ 
    Now, let $\bracks{v_n}$ be a sequence in $X$ defined as
    \begin{align*}
    v_1 &= \parens{1,\ 0,\ \cdots} \\
    v_2 &= \parens{1,\ \frac{1}{2},\ 0,\ \cdots} \\
    v_3 &= \parens{1,\ \frac{1}{2},\ \frac{1}{3},\ 0,\ \cdots} \\
    v_4 &= \parens{1,\ \frac{1}{2},\ \frac{1}{3},\ \frac{1}{4},\ 
    0,\ \cdots} \\
    &\vdots \\
    v_n &= \parens{1,\ \frac{1}{2},\ \frac{1}{3},\ \cdots,\ 
    \frac{1}{n-1},\ \frac{1}{n},\ 0,\ \cdots} \\
    \end{align*}
    We'll show that $\bracks{v_n}$ converges and is Cauchy by showing
    that it satisfies
    $$\forall \vep > 0, \exists N \in \N: \forall n, k \in \N,
    n \geq N,\ \norm{v_{n+k} - v_n}_\infty < \vep$$
    Now, notice that 
    \begin{align*}
    v_{n+k} - v_n &= \parens{1-1,\ \frac{1}{2} - \frac{1}{2},\ 
    \cdots,\ \frac{1}{n-1} - \frac{1}{n-1},\ \frac{1}{n} - 
    \frac{1}{n},\ \frac{1}{n+1},\ \cdots,\ \frac{1}{n+k},\ 0,\ 
    \cdots} \\
    &= \parens{0,\
    \cdots,\ 0,\ \frac{1}{n+1},\ \frac{1}{n+2},\ \cdots,\ 
    \frac{1}{n+k},\ 0,\ 0,\ 
    \cdots} \\
    \end{align*}
    so, effectively, the norm of this difference is
    \begin{align*}
    \norm{v_{n+k} - v_n}_\infty &= \max\bracks{\abs{\frac{1}{n+1}},
    \cdots,\abs{\frac{1}{n+k}}} \\
    &= \abs{\frac{1}{n+1}} = \frac{1}{n+1}
    \end{align*}
    So let $\vep = 1/n$, because $\norm{v_{n+k} - v_n}_\infty < 1/n$
    from the last equation, and 
    $$\vep = \frac{1}{n} \implies n = \frac{1}{\vep} \implies N 
    = \ceiling{\frac{1}{\vep}}$$
    Now, with this choice of $N$:
    $$\forall \vep > 0, N=\ceiling{\frac{1}{\vep}}: 
    \forall n, k \in \N,
    n \geq N,\ \norm{v_{n+k} - v_n}_\infty < \vep$$
    and $\bracks{v_n}$ is a Cauchy sequence. So it's limit is
    $$\lim_{n\to\infty}v_n  =
    \parens{1,\ \frac{1}{2},\ \frac{1}{3},\ \frac{1}{4},\ 
    \frac{1}{5},\ \cdots} = v$$
    However, $v \notin X$ because there is no finite number of 
    indices past which every index is 0. This contradicts our 
    assumption that $X$ is complete, so $X$ is not complete. 
    \end{proof}
    
    \ee
    
    
    \item Let $d(x,y) = \abs{\arctan x - \arctan y},\ \forall x,y 
    \in \R$.
    \be[1.]
    \item Is $\parens{\R, d}$ a metric space?
    \begin{proof}
    $(\R, d)$ is a metric space. To prove that, we'll show that $d$ 
    is a metric on $\R$, let $x,y,z \in \R$.
    \textbf{Non-negativity and Identity}:\\
    $d$ is defined as the absolute value of a difference, so clearly
    it is non-negative. We'll show that $d$ satisfies the identity
    property from the left and the right.
    \be
    \item[$\Longrightarrow$:]
    If $d(x,y) = 0$, this means that 
    $$\abs{\arctan x - \arctan y} = 0 \implies \arctan x = \arctan y
    $$
    $\arctan$ is an injective function, because of it's definition 
    as the inverse of the $\tan$ function and 
    $$\dd{t}\parens{\arctan{t}} = \frac{1}{t^2 + 1} > 0,\ \forall t
    \in \R$$
    so we can conclude that 
    $$\arctan x = \arctan y \implies x = y$$
    as desired.
    
    \item[$\Longleftarrow$:]
    We have that $x = y$, therefore
    \begin{align*}
    x &= y \\
    \arctan x &= \arctan y \\
    \arctan x - \arctan y &= 0 \\
    \abs{\arctan x - \arctan y} &= \abs{0} \\
    \implies d(x,y) = 0
    \end{align*}
    which is what we wanted to show.
    \ee
    
    \textbf{Symmetry}:\\
    To show that $d$ has the symmetry property, we'll use properties
    of $\abs{\cdot}$:
    \begin{align*}
    d(x,y) &= \abs{\arctan{x} - \arctan{y}} \\
    &= \abs{-\parens{\arctan{y} - \arctan{x}}} \\
    &= \abs{\arctan{y} - \arctan{x}} \\
    &= d(y,x)
    \end{align*}
    which is what we wanted to show.
    
    \textbf{Triangle Inequality}:\\
    Again, by the properties of $\abs{\cdot}$:
    \begin{align*}
    d(x,y) &= \abs{\arctan x - \arctan y} \\
    &= \abs{\arctan x - \arctan z + \arctan z - \arctan y} \\
    &\leq \abs{\arctan x - \arctan z} + 
    \abs{\arctan z - \arctan y} \\
    &= d(x,z) + d(z,y)
    \end{align*}
    So, $d$ respects the triangle inequality.\\\\
    $d$ satisfies the properties of a metric on $\R$, so 
    $\parens{\R, d}$ is a metric space.
    \end{proof}
    
    \item Is $\parens{\R, d}$ a bounded space?
    \begin{proof}
    $\parens{\R, d}$ is a bounded space. As we know 
    $$-\frac{\pi}{2} < \arctan t < \frac{\pi}{2},\ \forall t \in \R$$
    So the greatest possible distance between any 2 elements of $\R$
    is
    \begin{gather*} 
    d(x,y) = \abs{\arctan x - \arctan y} < 
    \abs{\frac{\pi}{2} - \parens{-\frac{\pi}{2}}} = \abs{\frac{\pi 
    + \pi}{2}} = \pi \\
    \implies d(x,y) < \pi,\ \forall x,y \in \R
    \end{gather*}
    So, $\parens{\R, d}$ is a bounded spaces.
    \end{proof}
    
    \item Find the expressions of the open balls $B_2(0),\ B_4(0),\
    B_4(1)$. What can you observe?
    \begin{proof}[Answer]
    The expressions for these open balls are:
    \begin{align*}
    B_2(0) &= \bracks{y \in \R\ \big|\ d(0,y) = \abs{\arctan y} < 2} 
    \\
    B_4(0) &= \bracks{y \in \R\ \big|\ d(0,y) = \abs{\arctan y} < 4}
    \\
    B_4(1) &= \bracks{y \in \R\ \big|\ d(1,y) = 
    \abs{\arctan 1 - \arctan y} < 4} \\
    \end{align*}
    Because of the bounded nature of the $\arctan$ function the
    inequalities of each open balls' definition are satisfied for all
    elements in $\R$, so
    $$B_2(0) = B_4(0) = B_4(1) = \R$$
    \end{proof}
    
    \item Let us denote $\tilde{d}(x,y) = \abs{x-y}$ the usual metric
    on $\R$. Show that $d$ and $\tilde{d}$ are not equivalent metrics
    (same as definition as for equivalent norms).
    \begin{proof}
    For $d$ and $\tilde{d}$ to be equivalent metrics, it must be the
    case that
    $$\exists c, c' \in \R^+ : \forall x,y \in \R, 
    \tilde{d}(x,y) \leq cd(x,y)\ \wedge\ d(x,y) \leq c'\tilde{d}(x,y)
    $$
    but for any possible choice of $c$, there exist $x$ and $y$ that
    violate 
    \begin{gather*}
    \tilde{d}(x,y) \leq cd(x,y) \\
    \implies \abs{x-y} \leq c\abs{\arctan x - \arctan y}
    \end{gather*}
    because $c\abs{\arctan x - \arctan y} < c\pi$. Any choice of 
    $x$ and $y$ such that $\abs{x-y} \geq c\pi$ will violate that 
    inequality and so $d$ and $\tilde{d}$ are not equivalent metrics.
    \end{proof}
    
    \ee
    
        
    \item Let $\mathcal{C}^1\parens{[a,b]}$ the set of real-valued 
    continuous functions defined on $[a,b]$, differentiable with
    continuous derivatives on $[a,b]$. Define the function
    $$\forall f,g \in \mathcal{C}^1\parens{[a,b]},\ d(f,g) = \sup
    _{x\in [a,b]}\abs{f'(x) - g'(x)}$$
    where $f'$ denotes the derivative of $f$. Is $d$ a metric on 
    $\mathcal{C}^1\parens{[a,b]}$?
    \begin{proof}
	$d$ is not a metric on $\mathcal{C}^1\parens{\sqbracks{a,b}}$, 
	because it doesn't satisfy one of the properties of a metric, 
	namely:
	$$\forall f,g \in \mathcal{C}^1\parens{\sqbracks{a,b}},\ d(f,g) =
	0 \iff f=g$$
	
	Indeed, let $f \in \mathcal{C}^1\parens{\sqbracks{a,b}}$ and $g = 
	f + c,\ c \in \R$. So clearly, $g \in \mathcal{C}
	^1\parens{\sqbracks{a,b}}$ and $f \neq g$, yet:
	$$d(f,g) = \sup_{x\in[a,b]}\abs{f'(x) - g'(x)} = 0$$
	because $f$ and $g$ only differ by a constant, it is the case 
	that $f'(x) = g'(x), 
	\forall x \in[a,b]$ therefore	
	$$\sup_{x\in[a,b]}\abs{f'(x) - g'(x)} = \sup_{x\in[a,b]}
	\abs{f'(x) - f'(x)} = \sup_{x\in[a,b]}0 = 0$$
	As such, $d$ does not satisfy one of the properties of a metric, 
	and cannot be a metric on $\mathcal{C}^1\parens{\sqbracks{a,b}}$. 
	\end{proof}
    
    
\ee
\noindent\makebox[\linewidth]{\rule{\paperwidth}{0.4pt}}
	
\end{document}
